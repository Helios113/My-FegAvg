{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import copy\n",
    "import torch\n",
    "from client import Client\n",
    "from models import SLC, MLP\n",
    "from dataset import FedDataset, get_data\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from math import ceil\n",
    "import pandas as pd\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 100\n",
    "test_freq = 1\n",
    "local_epochs = 5\n",
    "\n",
    "# Determine hardware availability\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"  # NVIDIA GPU\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"  # Apple GPU\n",
    "else:\n",
    "    device = \"cpu\"  # Defaults to CPU if NVIDIA GPU/Apple GPU aren't available\n",
    "\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "# Test parameters\n",
    "temporal_len = 10\n",
    "\n",
    "transient_dim = 4\n",
    "output_dim = 13\n",
    "hidden_dims = [32]\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "n = 4\n",
    "learning_rate = 1e-2\n",
    "momentum = 0\n",
    "optimizer = \"SGD\"\n",
    "\n",
    "alpha = 1\n",
    "alpha_per_modality = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_series_name = \"test_z\"\n",
    "main_folder = \"test_results\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.isdir(main_folder+'/'+test_series_name):\n",
    "#     train_data, test_data, train_dict, test_dict = get_data(\n",
    "#         \"data/data_all.csv\", n)\n",
    "#     num_batch = ceil(max([len(i) for i in test_dict.values()])/batch_size)\n",
    "#     os.mkdir(main_folder+'/'+test_series_name)\n",
    "#     with open(main_folder+'/'+test_series_name+'/train_dict.pkl', 'wb') as f:\n",
    "#         pickle.dump(train_dict, f)\n",
    "#     with open(main_folder+'/'+test_series_name+'/test_dict.pkl', 'wb') as f:\n",
    "#         pickle.dump(test_dict, f)\n",
    "#     torch.save(train_data, main_folder+'/'+test_series_name+'/train_data')\n",
    "\n",
    "#     torch.save(test_data, main_folder+'/'+test_series_name+'/test_data')\n",
    "# else:\n",
    "#     train_dict = {}\n",
    "#     test_dict = {}\n",
    "#     with open(main_folder+'/'+test_series_name+'/train_dict.pkl', \"rb\") as input_file:\n",
    "#         train_dict = pickle.load(input_file)\n",
    "#     with open(main_folder+'/'+test_series_name+'/test_dict.pkl', \"rb\") as input_file:\n",
    "#         test_dict = pickle.load(input_file)\n",
    "\n",
    "#     train_data = torch.load(main_folder+'/'+test_series_name+'/train_data')\n",
    "\n",
    "#     test_data = torch.load(main_folder+'/'+test_series_name+'/test_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nClients = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_mod = {\n",
    "#     \"accChest\": [1, 2, 3],\n",
    "#     \"EKG\": [4, 5],\n",
    "#     \"accLa\": [6, 7, 8],\n",
    "#     \"gyroLa\": [9, 10, 11],\n",
    "#     \"magLa\": [12, 13, 14],\n",
    "#     \"accRa\": [15, 16, 17],\n",
    "#     \"gyroRa\": [18, 19, 20],\n",
    "#     \"magRa\": [21, 22, 23]\n",
    "#  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mod = {\n",
    "    \"all\": [\n",
    "        1,\n",
    "        2,\n",
    "        3,\n",
    "        6,\n",
    "        7,\n",
    "        8,\n",
    "        15,\n",
    "        16,\n",
    "        17,\n",
    "        9,\n",
    "        10,\n",
    "        11,\n",
    "        18,\n",
    "        19,\n",
    "        20,\n",
    "        12,\n",
    "        13,\n",
    "        14,\n",
    "        21,\n",
    "        22,\n",
    "        23,\n",
    "    ],\n",
    "    \"acc\": [1, 2, 3, 6, 7, 8, 15, 16, 17],\n",
    "    \"gyro\": [9, 10, 11, 18, 19, 20],\n",
    "    \"mag\": [12, 13, 14, 21, 22, 23],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities = [\n",
    "    {\"gyro\": [9, 10, 11, 18, 19, 20]},\n",
    "    {\"gyro\": [9, 10, 11, 18, 19, 20]},\n",
    "    {\"gyro\": [9, 10, 11, 18, 19, 20]},\n",
    "    {\"gyro\": [9, 10, 11, 18, 19, 20]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode\n",
    "federatedGlob = True\n",
    "federatedLoc = True\n",
    "lg_frac = 0\n",
    "\n",
    "# result lists\n",
    "train_performance = None\n",
    "test_performance = {i: None for i in range(n)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clients = []\n",
    "# if federatedLoc:\n",
    "#     uni_loc = SLC(all_mod, hidden_dims, transient_dim, False)\n",
    "# uni_glob = MLP(transient_dim, output_dim)\n",
    "# # Generate clients\n",
    "# for i in range(n):\n",
    "#     local_mod = SLC(modalities[i], hidden_dims, transient_dim, False)\n",
    "#     glob_mod = MLP(transient_dim, output_dim)\n",
    "\n",
    "#     # if federatedLoc:\n",
    "#     #     s_dict = {}\n",
    "#     #     local_dict = uni_loc.state_dict()\n",
    "#     #     for k in local_mod.state_dict():\n",
    "#     #         s_dict[k] = copy.deepcopy(local_dict[k])\n",
    "#     #     local_mod.load_state_dict(s_dict)\n",
    "#     # if federatedGlob:\n",
    "#     #     s_dict = {}\n",
    "#     #     global_dict = uni_glob.state_dict()\n",
    "#     #     for k in glob_mod.state_dict():\n",
    "#     #         s_dict[k] = copy.deepcopy(global_dict[k])\n",
    "#     #     glob_mod.load_state_dict(s_dict)\n",
    "\n",
    "#     clients.append(\n",
    "#         Client(\n",
    "#             glob_mod,\n",
    "#             local_mod,\n",
    "#             local_epochs,\n",
    "#             learning_rate=learning_rate,\n",
    "#             optimizer=optimizer,\n",
    "#             device=device,\n",
    "#             momentum=momentum,\n",
    "#         )\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_train, data_test = get_data(\"data/data_all.csv\", 4, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = []\n",
    "\n",
    "# Populate clients\n",
    "for i in range(nClients):\n",
    "    clients.append(\n",
    "        Client(\n",
    "            MLP(transient_dim, output_dim),\n",
    "            SLC(modalities[i], hidden_dims, transient_dim, False),\n",
    "            DataLoader(FedDataset(data_train[i], device),\n",
    "                       batch_size=32),\n",
    "            local_epochs,\n",
    "            learning_rate,\n",
    "            \"Adam\",\n",
    "            device=device\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_entry = 0\n",
    "\n",
    "for round in range(rounds):\n",
    "    # Global params for FL\n",
    "    w_glob_tmp = None\n",
    "\n",
    "    # Local params for FL\n",
    "    w_loc_tmp = None\n",
    "\n",
    "    # Count of encounters of each param\n",
    "    w_loc_tmp_count = None\n",
    "    if round > (1 - lg_frac) * rounds:\n",
    "        federatedLoc = False\n",
    "    print_loss = []\n",
    "    for client in range(n):\n",
    "        w_glob_ret, w_local_ret, performance = clients[client].train()\n",
    "\n",
    "        print_loss.append(np.average(performance))\n",
    "\n",
    "        if federatedGlob:\n",
    "            if w_glob_tmp is None:\n",
    "                w_glob_tmp = copy.deepcopy(w_glob_ret)\n",
    "            else:\n",
    "                for k in w_glob_ret:\n",
    "                    w_glob_tmp[k] += w_glob_ret[k]\n",
    "\n",
    "        if federatedLoc:\n",
    "            if alpha_per_modality:\n",
    "                factor = (\n",
    "                    1 if len(w_local_ret) / 8 == 1 else len(w_local_ret) / 8 * alpha\n",
    "                )\n",
    "            else:\n",
    "                factor = 1 if len(w_local_ret) / 8 == 1 else alpha\n",
    "\n",
    "            if w_loc_tmp is None:\n",
    "                w_loc_tmp = {}\n",
    "                w_loc_tmp_count = {}\n",
    "            for k in w_local_ret.keys():\n",
    "                if k not in w_loc_tmp:\n",
    "                    w_loc_tmp[k] = factor * w_local_ret[k]\n",
    "                    w_loc_tmp_count[k] = factor\n",
    "                else:\n",
    "                    w_loc_tmp[k] += factor * w_local_ret[k]\n",
    "                    w_loc_tmp_count[k] += factor\n",
    "\n",
    "        # performance = clients[client].test()\n",
    "        # if test_performance[client] is None:\n",
    "        #     test_performance[client] = copy.deepcopy(performance)\n",
    "        # else:\n",
    "        #     test_performance[client] = np.hstack(\n",
    "        #         (test_performance[client], performance)\n",
    "        #     )\n",
    "\n",
    "    if train_performance is None:\n",
    "        train_performance = np.array(print_loss).reshape(1, -1)\n",
    "    else:\n",
    "        train_performance = np.vstack((train_performance, np.array(print_loss)))\n",
    "\n",
    "    # get weighted average for global weights\n",
    "    if federatedGlob:\n",
    "        for k in w_glob_tmp.keys():\n",
    "            w_glob_tmp[k] = torch.div(w_glob_tmp[k], n)\n",
    "    if federatedLoc:\n",
    "        for k in w_loc_tmp.keys():\n",
    "            w_loc_tmp[k] = torch.div(w_loc_tmp[k], w_loc_tmp_count[k])\n",
    "\n",
    "    # copy weights to each client based on mode\n",
    "    if federatedGlob or federatedLoc:\n",
    "        for client in range(n):\n",
    "            clients[client].load_params(w_glob_tmp, w_loc_tmp)\n",
    "\n",
    "\n",
    "    plt.clf()\n",
    "    plt.plot(train_performance, label=[1, 2, 3, 4])\n",
    "    plt.legend()\n",
    "\n",
    "    print(modalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = main_folder + \"/\" + test_series_name + \"/test_015\"\n",
    "\n",
    "# if os.path.isdir(save_path) is False:\n",
    "#     os.mkdir(\n",
    "#         save_path,\n",
    "#     )\n",
    "#     torch.save(test_performance, f\"{save_path}/test_data\")\n",
    "#     info_dict = {\n",
    "#         \"Num of clients\": n,\n",
    "#         \"Learning rate\": learning_rate,\n",
    "#         \"Federated Global\": federatedGlob,\n",
    "#         \"Federated Local\": federatedLoc,\n",
    "#         \"Batch Size\": batch_size,\n",
    "#         \"Global rounds\": rounds,\n",
    "#         \"Local epochs\": local_epochs,\n",
    "#         \"Clients\": clients,\n",
    "#         \"Modalities\": modalities,\n",
    "#         \"Optimizer\": optimizer,\n",
    "#         \"Temporal length\": temporal_len,\n",
    "#         \"Transient dimension\": transient_dim,\n",
    "#         \"Hidden dimensions\": hidden_dims,\n",
    "#         \"alpha\": alpha,\n",
    "#         \"alpha_per_modality\": alpha_per_modality,\n",
    "#     }\n",
    "#     with open(f\"{save_path}/test_info.txt\", \"w\") as f:\n",
    "#         f.write(info_dict.__repr__())\n",
    "\n",
    "#     for i in range(n):\n",
    "#         torch.save(clients[i].model.state_dict(), f\"{save_path}/dev{i}_model\")\n",
    "# else:\n",
    "#     print(\"test exists\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e5ea2ed259c2b90ed99a747e84043e0f5af35635ee5482f3cd465e671e6563a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
